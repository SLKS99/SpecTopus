"""
Demo script for analyzing PL spectrum data using the fitting agent.
This script demonstrates the complete workflow by calling functions from fitting_agent.py.
"""

import os
import json
import shutil
from tools.fitting_agent import (
    LLMClient, 
    build_agent_config,
    curate_dataset,
    run_complete_analysis
)

# Ensure output directory exists
OUTPUT_DIR = "output"
os.makedirs(OUTPUT_DIR, exist_ok=True)


def main():
    print("=== PL Spectrum Analysis Demo ===")
    
    # Set up the API key
    # os.environ["GOOGLE_API_KEY"] = "AIzaSyB-3zT32fNofbvF7_WbR1UfY0RCm2QglZw"

    # Initialize LLM client
    print("Initializing LLM client...")
    # llm = LLMClient()
    llm = LLMClient(provider="openai", model_id="gpt-4o-mini")
    
    # Configure data processing
    print("Setting up data configuration...")
    config = build_agent_config(
        data_csv="PEASnPbI4-Toluene.csv",           # Your PL data file
        composition_csv="2D-3D (1).csv",            # Your composition file
        read_selection="1",                         # Use read 1
        wells_to_ignore=None,                       # Don't ignore any wells
        start_wavelength=500,                       # Emission start 500nm
        end_wavelength=850,                         # Emission stop 850nm
        wavelength_step_size=1,                     # Step 1nm
        fill_na_value=0.0
    )
    
    print("Loading and curating dataset...")
    try:
        # Load and process the data
        curated = curate_dataset(config)
        print("Available wells:", curated["wells"][:10], "...")
        print("Available reads:", curated["reads"])
        
        # Analyze all wells for read 1
        available_wells = curated["wells"]
        print(f"\nFound {len(available_wells)} wells to analyze")
        
        # Run complete analysis for all wells
        print("\n=== Running Complete Analysis for All Wells ===")
        all_results = []
        
        for i, well_name in enumerate(available_wells):
            print(f"\n--- Analyzing Well {well_name} ({i+1}/{len(available_wells)}) ---")
            
            try:
                results = run_complete_analysis(
                    config=config,
                    well_name=well_name,
                    llm=llm,
                    read=1,
                    max_peaks=3,
                    model_kind="gaussian",
                    r2_target=0.90,
                    max_attempts=3
                )
                all_results.append(results)
                
                # Quick summary for each well
                fit_result = results['fit_result']
                print(f"‚úÖ {well_name}: {len(results['llm_numeric_result'].peaks)} peaks, R¬≤={fit_result.stats.r2:.3f}")
                
                # Save each well's results as JSON
                output_path = os.path.join(OUTPUT_DIR, f"{well_name}_results.json")
                with open(output_path, "w") as f:
                    json.dump(results, f, indent=2, default=str)
                print(f"üìÅ Results saved to {output_path}")
                
                # Move any generated files (png, csv, etc.) into output/
                if "files" in results:
                    for file_type, filename in results["files"].items():
                        if os.path.exists(filename):
                            dest = os.path.join(OUTPUT_DIR, os.path.basename(filename))
                            shutil.move(filename, dest)
                            results["files"][file_type] = dest  # update path
                            print(f"üìÇ {file_type} file moved to {dest}")
                
            except Exception as e:
                print(f"‚ùå {well_name}: Error - {e}")
                continue
        
        # Display summary results
        print(f"\n=== Analysis Summary ===")
        print(f"Successfully analyzed {len(all_results)} out of {len(available_wells)} wells")
        
        # Save overall summary
        summary_path = os.path.join(OUTPUT_DIR, "analysis_summary.txt")
        with open(summary_path, "w") as f:
            f.write(f"Successfully analyzed {len(all_results)} out of {len(available_wells)} wells\n")
            for res in all_results:
                well_name = res['well_name']
                r2 = res['fit_result'].stats.r2 if res['fit_result'].success else "N/A"
                f.write(f"{well_name}: R¬≤={r2}\n")
        print(f"üìä Summary saved to {summary_path}")
        
        # Show top performing wells
        successful_results = [r for r in all_results if r['fit_result'].success]
        if successful_results:
            # Sort by R¬≤
            successful_results.sort(key=lambda x: x['fit_result'].stats.r2, reverse=True)
            
            print(f"\n=== Top 5 Best Fitting Wells ===")
            for i, results in enumerate(successful_results[:5]):
                well_name = results['well_name']
                fit_result = results['fit_result']
                print(f"{i+1}. {well_name}: R¬≤={fit_result.stats.r2:.4f}, {len(fit_result.peaks)} peaks")
        
        # Show detailed results for first well as example
        if all_results:
            example_results = all_results[0]
            well_name = example_results['well_name']
            
            print(f"\n=== Detailed Results Example (Well {well_name}) ===")
            
            # LLM Results
            print(f"\nLLM Numeric Analysis found {len(example_results['llm_numeric_result'].peaks)} peaks:")
            for i, peak in enumerate(example_results['llm_numeric_result'].peaks):
                print(f"  Peak {i+1}: center={peak.center:.1f} nm, height={peak.height:.1f}, fwhm={peak.fwhm}")
            
            print(f"\nLLM Image Analysis found {len(example_results['llm_image_result'].peaks)} peaks:")
            for i, peak in enumerate(example_results['llm_image_result'].peaks):
                print(f"  Peak {i+1}: center={peak.center:.1f} nm, height={peak.height:.1f}, fwhm={peak.fwhm}")
            
            # Fitting Results
            fit_result = example_results['fit_result']
            print(f"\n=== lmfit Fitting Results ===")
            print(f"Fitting successful: {fit_result.success}")
            print(f"R¬≤ = {fit_result.stats.r2:.4f}")
            print(f"Reduced œá¬≤ = {fit_result.stats.redchi:.2f}")
            print(f"AIC = {fit_result.stats.aic:.2f}")
            print(f"BIC = {fit_result.stats.bic:.2f}")
            
            print(f"\nPeak Parameters:")
            for i, peak in enumerate(fit_result.peaks):
                print(f"  Peak {i+1}:")
                print(f"    Position: {peak.center:.2f} nm")
                print(f"    Intensity: {peak.height:.1f}")
                print(f"    FWHM: {peak.fwhm:.2f} nm" if peak.fwhm else "    FWHM: N/A")
            
            # Quality Assessment
            print(f"\n=== Fitting Quality Assessment ===")
            for assessment_type, message in example_results['quality_assessment'].items():
                print(message)
            
            # Files Created (example)
            print(f"\n=== Files Created (Example for {well_name}) ===")
            for file_type, filename in example_results['files'].items():
                print(f"- {file_type}: {filename}")
        
        print(f"\n=== Demo completed! ===")
        print(f"Analyzed {len(all_results)} wells. Check the generated files in '{OUTPUT_DIR}' for detailed results.")
        
    except Exception as e:
        print(f"Error processing data: {e}")
        print("Make sure your CSV files are in the correct format and accessible.")

if __name__ == "__main__":
    main()
